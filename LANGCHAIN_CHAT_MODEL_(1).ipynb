{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhinesh342/langchain-college-admin/blob/main/LANGCHAIN_CHAT_MODEL_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This project is a simple chatbot powered by a Large Language Model (LLM) from OpenAI. It uses the LangChain framework to act as \"glue\" for our application and is hosted with a user-friendly web interface created by Gradio.** ** This chat bot is a university admin. We're building this project to learn about AI application development step-by-step**."
      ],
      "metadata": {
        "id": "AVHU-uYUZM_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LANGCHAIN:**\n",
        "LangChain is an open-source framework,It simplifies the process of connecting LLMs like OpenAI's GPT models to external data sources and other tools.\n",
        "The name \"LangChain\" comes from the idea of \"chaining\" together different components to create more complex, powerful applications."
      ],
      "metadata": {
        "id": "-GWGQBWlZ4zf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 1:**\n",
        "\n",
        " Installing neccassary libraries:\n",
        "  \n",
        "    - langchain-openai to connect to OpenAI's models\n",
        "    - Gradio to create a simple web-based UI"
      ],
      "metadata": {
        "id": "OjEmLDXQafur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VmD4ehqYMkfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b218368c-bd8f-4ccd-f78b-919f2fa55fc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/447.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain-openai gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 2: **\n",
        "\n",
        "This code block is a standard and secure way to handle API keys in Google Colab. It prevents us from hard-coding sensitive information directly into your notebook."
      ],
      "metadata": {
        "id": "IHkrKINzcDus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata #from google.colab import  This module provides a way to interact with our Colab Secrets\n",
        "import os # To manage environment variables\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "ZH8ofCKLNQ06"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 3:\n",
        "\n",
        "Here we are creating an instance of a chat model from OpenAI that LangChain can use. It's the central component that gives your chatbot its intelligence."
      ],
      "metadata": {
        "id": "E2qR0khTeAx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "J9AY_4tbNS2t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 4:\n",
        "\n",
        "This code creates a ChatPromptTemplate, which is a reusable and structured set of instructions for a chat-based language model.\n",
        "\n",
        "It uses the from_messages method to define a list of messages, each with a specific role, such as \"system\" (for giving the AI its identity and rules) and \"user\" (for a placeholder where the user's question will go)."
      ],
      "metadata": {
        "id": "TN6WpAZAfB6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\n",
        "        \"system\",\n",
        "        (\n",
        "            \"You are a professional and discerning university management admin. \"\n",
        "            \"Your goal is to evaluate a tech product for potential purchase by the university. \"\n",
        "            \"The user is a seller trying to sell you their product. \"\n",
        "            \"Your behavior should follow these rules:\\n\"\n",
        "            \"- Start by asking the user to describe their product and its benefits to the university.\\n\"\n",
        "            \"- Ask detailed follow-up questions about features and pricing.\\n\"\n",
        "            \"- You are on a budget. Try to negotiate the price down by at least 20%.\\n\"\n",
        "            \"- Assess the product's value proposition and determine if it truly meets the university's needs.\\n\"\n",
        "            \"- After the negotiation, make a final decision on whether to buy or not to buy the product, explaining your reasoning clearly.\"\n",
        "      )\n",
        "    ),\n",
        "    (\"user\", \"{input}\")\n",
        "])"
      ],
      "metadata": {
        "id": "fAjwAGXmNUzW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 5:\n",
        "Creating a chain\n",
        "\n",
        "It is core of our LangChain application. It uses the LangChain Expression Language (LCEL) to create a simple, declarative pipeline (or \"chain\") that tells the application exactly what to do."
      ],
      "metadata": {
        "id": "nmFJTDpdfZNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm"
      ],
      "metadata": {
        "id": "hrgoyd9GNWpv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 6:\n",
        "\n",
        "Creating a function to handle the chat logic\n"
      ],
      "metadata": {
        "id": "WBu-lsxKf_x7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_chat(user_input, chat_history):\n",
        "    \"\"\"\n",
        "    This function handles the chatbot's core logic.\n",
        "    It takes user input and returns the chatbot's response.\n",
        "    \"\"\"\n",
        "    # We simply invoke the LangChain with the user's message.\n",
        "    response = chain.invoke({\"input\": user_input})\n",
        "    return response.content"
      ],
      "metadata": {
        "id": "19Va3eTyNYce"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 7:\n",
        "\n",
        "This code creates and launches a Gradio web-based user interface (UI) for your chatbot.\n",
        "\n",
        "- gr.ChatInterface, It handles the entire look and feel of a chat application for you, including the text input box, the chat history display, and the send button."
      ],
      "metadata": {
        "id": "5PgcbH3HgjEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "demo = gr.ChatInterface(\n",
        "    fn=handle_chat,\n",
        "    title=\"NEXA:university management admin\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Launch the UI. The 'share=True' argument generates a public link.\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "collapsed": true,
        "id": "CzRoCF2kVgWR",
        "outputId": "a650e9b3-6dd0-4f31-8578-fb79a656752d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gradio/chat_interface.py:345: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c57a21ea5f020115ab.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c57a21ea5f020115ab.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}